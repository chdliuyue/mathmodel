"""Transfer learning pipeline for adapting the source-domain model to the target domain."""
from __future__ import annotations

from collections import Counter
from dataclasses import dataclass, field
from typing import Any, Dict, List, Mapping, Optional, Sequence, Tuple

import logging

import numpy as np
import pandas as pd
from sklearn.base import clone
from sklearn.pipeline import Pipeline
from sklearn.neighbors import NearestNeighbors

from ...analysis.feature_analysis import compute_domain_alignment_metrics
from ...analysis.feature_analysis import run_tsne  # re-export convenience
from ...modeling import SourceDiagnosisConfig, TrainingResult, train_source_domain_model
from .features import TimeFrequencyConfig, extract_time_frequency_features
from .segment_loader import SegmentFetcher

LOGGER = logging.getLogger(__name__)


@dataclass
class PseudoLabelConfig:
    """Configuration governing pseudo-labelling on target data."""

    enabled: bool = True
    confidence_threshold: float = 0.95
    max_iterations: int = 2
    max_ratio: float = 0.4  # Relative to the number of labelled source samples
    consistency_threshold: float = 0.6


@dataclass
class TransferConfig:
    """Aggregate configuration for the transfer learning pipeline."""

    diagnosis: SourceDiagnosisConfig
    time_frequency: TimeFrequencyConfig = field(default_factory=TimeFrequencyConfig)
    pseudo_label: PseudoLabelConfig = field(default_factory=PseudoLabelConfig)
    metadata_columns: Sequence[str] = ("file_id", "channel", "segment_index", "start_sample", "end_sample", "rpm")


@dataclass
class TransferResult:
    """Container bundling all artefacts generated by the transfer pipeline."""

    base_result: TrainingResult
    final_pipeline: Pipeline
    feature_columns: List[str]
    modal_feature_groups: Dict[str, List[str]]
    source_features: pd.DataFrame
    target_features: pd.DataFrame
    combined_before: pd.DataFrame
    combined_aligned: pd.DataFrame
    alignment_before: pd.DataFrame
    alignment_after: pd.DataFrame
    initial_predictions: pd.DataFrame
    final_predictions: pd.DataFrame
    pseudo_labels: pd.DataFrame
    pseudo_label_history: List[Dict[str, float]]
    time_frequency_features: List[str]
    consistency_features: List[str]
    pseudo_quality: pd.DataFrame


def _infer_sampling_rate(row: Mapping[str, any]) -> float:
    sampling_rate = row.get("sampling_rate")
    try:
        rate = float(sampling_rate)
        if np.isfinite(rate) and rate > 0:
            return rate
    except Exception:
        pass
    length = row.get("segment_length")
    duration = row.get("segment_duration")
    try:
        length_val = float(length)
        duration_val = float(duration)
        if np.isfinite(length_val) and np.isfinite(duration_val) and duration_val > 0:
            return length_val / duration_val
    except Exception:
        pass
    return 1.0


def _augment_with_time_frequency(frame: pd.DataFrame, config: TransferConfig, fetcher: SegmentFetcher) -> pd.DataFrame:
    if frame.empty:
        return frame.copy()

    features: List[Dict[str, float]] = []
    missing_segments = 0
    for _, row in frame.iterrows():
        segment = fetcher.get_segment(row)
        if segment is None or len(segment) == 0:
            features.append({})
            missing_segments += 1
            continue
        sampling_rate = _infer_sampling_rate(row)
        tf_features = extract_time_frequency_features(segment, sampling_rate, config.time_frequency)
        features.append(tf_features)
    if missing_segments:
        LOGGER.warning("Time-frequency features skipped for %s segments due to missing data", missing_segments)
    tf_frame = pd.DataFrame(features)
    return pd.concat([frame.reset_index(drop=True), tf_frame], axis=1)


def _ensure_dataset_column(frame: pd.DataFrame, value: str) -> pd.DataFrame:
    if "dataset" not in frame.columns:
        frame = frame.copy()
        frame["dataset"] = value
    return frame


def _set_target_statistics(pipeline: Pipeline, feature_matrix: np.ndarray) -> None:
    aligner = pipeline.named_steps.get("aligner")
    imputer = pipeline.named_steps.get("imputer")
    if imputer is None:
        X_target = feature_matrix
    else:
        X_target = imputer.transform(feature_matrix)
    if aligner is None or not getattr(aligner, "enabled", False):
        return
    mean = np.mean(X_target, axis=0)
    if X_target.shape[0] > 1:
        covariance = np.cov(X_target, rowvar=False)
    else:
        covariance = np.eye(X_target.shape[1])
    aligner.set_target_statistics(mean, covariance)


def _transform_aligned(pipeline: Pipeline, feature_matrix: np.ndarray) -> np.ndarray:
    imputer = pipeline.named_steps.get("imputer")
    aligner = pipeline.named_steps.get("aligner")
    X = feature_matrix
    if imputer is not None:
        X = imputer.transform(X)
    if aligner is not None and getattr(aligner, "enabled", False):
        X = aligner.transform(X)
    return X


def _select_metadata(frame: pd.DataFrame, columns: Sequence[str]) -> pd.DataFrame:
    available = [column for column in columns if column in frame.columns]
    return frame[available].reset_index(drop=True)


def _identify_modal_feature_groups(feature_columns: Sequence[str]) -> Dict[str, List[str]]:
    groups = {
        "time": [column for column in feature_columns if column.startswith("time_")],
        "stft": [column for column in feature_columns if column.startswith("tf_stft_")],
        "cwt": [column for column in feature_columns if column.startswith("tf_cwt_")],
        "mel": [column for column in feature_columns if column.startswith("tf_mel_")],
    }
    return {name: cols for name, cols in groups.items() if cols}


def _prepare_matrix(frame: pd.DataFrame, columns: Sequence[str]) -> np.ndarray:
    if not columns:
        return np.zeros((len(frame), 0), dtype=float)
    matrix = frame[list(columns)].astype(float).to_numpy(copy=True)
    if matrix.size == 0:
        return np.zeros((len(frame), len(columns)), dtype=float)
    with np.errstate(all="ignore"):
        col_means = np.nanmean(matrix, axis=0)
    col_means = np.where(np.isfinite(col_means), col_means, 0.0)
    nan_mask = np.isnan(matrix)
    if nan_mask.any():
        matrix[nan_mask] = np.take(col_means, np.where(nan_mask)[1])
    return np.nan_to_num(matrix, nan=0.0, posinf=0.0, neginf=0.0)


def _majority_vote(labels: Sequence[str]) -> str:
    counter = Counter(label for label in labels if label is not None and label != "")
    if not counter:
        return ""
    most_common = counter.most_common()
    top_count = most_common[0][1]
    top_labels = [label for label, count in most_common if count == top_count]
    return str(sorted(top_labels)[0])


def _nearest_modal_vote(
    source_matrix: np.ndarray,
    source_labels: Sequence[str],
    target_matrix: np.ndarray,
    n_neighbors: int = 5,
) -> Tuple[List[str], np.ndarray]:
    if source_matrix.size == 0 or target_matrix.size == 0:
        return [""] * len(target_matrix), np.zeros(len(target_matrix), dtype=float)
    neighbors = max(1, min(n_neighbors, source_matrix.shape[0]))
    model = NearestNeighbors(n_neighbors=neighbors, metric="euclidean")
    model.fit(source_matrix)
    distances, indices = model.kneighbors(target_matrix, return_distance=True)
    source_labels = np.asarray(list(source_labels), dtype=object)
    votes: List[str] = []
    for row in indices:
        labels = [str(source_labels[idx]) for idx in row]
        votes.append(_majority_vote(labels))
    mean_distances = distances.mean(axis=1) if distances.size else np.zeros(len(target_matrix), dtype=float)
    return votes, mean_distances


def _evaluate_multimodal_consistency(
    source_frame: pd.DataFrame,
    target_frame: pd.DataFrame,
    predicted_labels: Sequence[str],
    label_column: str,
    feature_groups: Dict[str, List[str]],
    n_neighbors: int = 5,
) -> pd.DataFrame:
    if not feature_groups:
        return pd.DataFrame(index=target_frame.index)

    label_series = source_frame[label_column]
    valid_mask = label_series.notna()
    label_series = label_series[valid_mask].astype(str)
    records: Dict[str, Any] = {
        "predicted_label": list(predicted_labels),
    }

    if label_series.empty:
        return pd.DataFrame(records, index=target_frame.index)

    for name, columns in feature_groups.items():
        src_matrix = _prepare_matrix(source_frame.loc[valid_mask], columns)
        tgt_matrix = _prepare_matrix(target_frame, columns)
        votes, distances = _nearest_modal_vote(src_matrix, label_series, tgt_matrix, n_neighbors=n_neighbors)
        records[f"{name}_vote"] = votes
        records[f"{name}_distance"] = distances
        predicted = np.asarray(predicted_labels, dtype=object)
        agreement = (predicted == np.asarray(votes, dtype=object)).astype(float)
        records[f"{name}_agree"] = agreement

    frame = pd.DataFrame(records, index=target_frame.index)
    agree_columns = [column for column in frame.columns if column.endswith("_agree")]
    if agree_columns:
        frame["consistency_score"] = frame[agree_columns].mean(axis=1)
    else:
        frame["consistency_score"] = 0.0
    return frame


def _predict_with_pipeline(
    pipeline: Pipeline,
    frame: pd.DataFrame,
    feature_columns: Sequence[str],
    metadata_columns: Sequence[str],
) -> pd.DataFrame:
    X = frame[feature_columns].astype(float)
    metadata = _select_metadata(frame, metadata_columns)
    metadata = metadata.reset_index(drop=True)
    predicted = pipeline.predict(X)
    result = metadata.copy()
    result["row_index"] = frame.index.to_numpy()
    result["predicted_label"] = predicted
    classifier = pipeline.named_steps.get("classifier")
    if classifier is not None and hasattr(classifier, "predict_proba"):
        proba = pipeline.predict_proba(X)
        classes = getattr(classifier, "classes_", [])
        for idx, class_name in enumerate(classes):
            result[f"probability_{class_name}"] = proba[:, idx]
        result["max_probability"] = proba.max(axis=1)
    return result


def _apply_pseudo_labelling(
    base_pipeline: Pipeline,
    feature_columns: Sequence[str],
    source_frame: pd.DataFrame,
    target_frame: pd.DataFrame,
    label_column: str,
    metadata_columns: Sequence[str],
    config: PseudoLabelConfig,
) -> Tuple[Pipeline, pd.DataFrame, List[Dict[str, float]], pd.DataFrame]:
    classifier = base_pipeline.named_steps.get("classifier")
    if not config.enabled or classifier is None or not hasattr(classifier, "predict_proba"):
        return base_pipeline, pd.DataFrame(), [], pd.DataFrame()

    X_source = source_frame[feature_columns].astype(float)
    y_source = source_frame[label_column].astype(str)
    X_target = target_frame[feature_columns].astype(float)

    current_pipeline = base_pipeline
    pseudo_records: List[pd.DataFrame] = []
    history: List[Dict[str, float]] = []
    quality_records: List[pd.DataFrame] = []
    used_mask = np.zeros(len(target_frame), dtype=bool)
    total_source = len(source_frame)
    if config.max_ratio > 0:
        max_total = max(int(round(config.max_ratio * total_source)), 1)
    else:
        max_total = None
    total_selected = 0
    feature_groups = _identify_modal_feature_groups(feature_columns)

    for iteration in range(config.max_iterations):
        proba = current_pipeline.predict_proba(X_target)
        predictions = current_pipeline.predict(X_target)
        max_proba = proba.max(axis=1)
        consistency_df = _evaluate_multimodal_consistency(
            source_frame,
            target_frame,
            predictions.astype(str),
            label_column,
            feature_groups,
        )
        consistency_scores = consistency_df.get("consistency_score", pd.Series(0.0, index=target_frame.index)).astype(float)
        candidate_mask = (max_proba >= config.confidence_threshold) & (~used_mask)
        candidate_mask &= consistency_scores.to_numpy() >= float(config.consistency_threshold)
        candidate_indices = np.where(candidate_mask)[0]
        if candidate_indices.size == 0:
            break
        if max_total is not None:
            remaining = max_total - total_selected
            if remaining <= 0:
                break
            candidate_indices = candidate_indices[:remaining]
        selected_rows = target_frame.iloc[candidate_indices].copy()
        selected_rows[label_column] = predictions[candidate_indices]
        selected_rows["pseudo_probability"] = max_proba[candidate_indices]
        selected_rows["pseudo_iteration"] = iteration + 1
        selected_rows["dataset"] = "target_pseudo"
        selected_rows["consistency_score"] = consistency_scores.iloc[candidate_indices].to_numpy()
        for column in consistency_df.columns:
            if column in selected_rows.columns:
                continue
            selected_rows[column] = consistency_df.iloc[candidate_indices][column].to_numpy()
        pseudo_records.append(selected_rows)
        used_mask[candidate_indices] = True
        total_selected += len(candidate_indices)

        combined = pd.concat([source_frame, *pseudo_records], ignore_index=True)
        X_combined = combined[feature_columns].astype(float)
        y_combined = combined[label_column].astype(str)
        next_pipeline = clone(base_pipeline)
        next_pipeline.fit(X_combined, y_combined)
        _set_target_statistics(next_pipeline, X_target)
        current_pipeline = next_pipeline

        selected_scores = consistency_scores.iloc[candidate_indices].to_numpy()
        history.append(
            {
                "iteration": float(iteration + 1),
                "new_samples": float(len(candidate_indices)),
                "cumulative_pseudo": float(total_selected),
                "threshold": float(config.confidence_threshold),
                "consistency_threshold": float(config.consistency_threshold),
                "probability_mean": float(np.mean(max_proba[candidate_indices])),
                "probability_min": float(np.min(max_proba[candidate_indices])),
                "probability_max": float(np.max(max_proba[candidate_indices])),
                "consistency_mean": float(np.mean(selected_scores)) if selected_scores.size else 0.0,
                "consistency_min": float(np.min(selected_scores)) if selected_scores.size else 0.0,
                "consistency_max": float(np.max(selected_scores)) if selected_scores.size else 0.0,
            }
        )

        metadata_subset = target_frame.iloc[candidate_indices][list(metadata_columns) if metadata_columns else []]
        quality_record = consistency_df.iloc[candidate_indices].copy()
        quality_record = quality_record.reset_index(drop=False).rename(columns={"index": "row_index"})
        quality_record["pseudo_iteration"] = iteration + 1
        quality_record["max_probability"] = max_proba[candidate_indices]
        quality_record["consistency_threshold"] = float(config.consistency_threshold)
        if not metadata_subset.empty:
            quality_record = pd.concat([quality_record.reset_index(drop=True), metadata_subset.reset_index(drop=True)], axis=1)
        quality_records.append(quality_record)

        if max_total is not None and total_selected >= max_total:
            break

    pseudo_df = pd.concat(pseudo_records, ignore_index=True) if pseudo_records else pd.DataFrame()
    quality_df = pd.concat(quality_records, ignore_index=True) if quality_records else pd.DataFrame()
    return current_pipeline, pseudo_df, history, quality_df


def run_transfer_learning(
    source_features: pd.DataFrame,
    target_features: pd.DataFrame,
    config: TransferConfig,
) -> TransferResult:
    LOGGER.info("Augmenting features with time-frequency descriptors ...")
    fetcher = SegmentFetcher()
    augmented_source = _augment_with_time_frequency(source_features, config, fetcher)
    augmented_target = _augment_with_time_frequency(target_features, config, fetcher)

    augmented_source = _ensure_dataset_column(augmented_source, "source")
    augmented_target = _ensure_dataset_column(augmented_target, "target")

    base_result = train_source_domain_model(augmented_source, config.diagnosis)
    feature_columns = base_result.feature_columns
    modal_feature_groups = _identify_modal_feature_groups(feature_columns)

    target_matrix = augmented_target[feature_columns].astype(float)
    _set_target_statistics(base_result.pipeline, target_matrix)

    initial_predictions = _predict_with_pipeline(
        base_result.pipeline,
        augmented_target,
        feature_columns,
        config.metadata_columns,
    )

    label_column = config.diagnosis.label_column
    source_visual = augmented_source[feature_columns].reset_index(drop=True)
    source_labels = augmented_source.get(label_column)
    if source_labels is not None:
        visual_labels = source_labels.fillna("未标注").astype(str)
    else:
        visual_labels = pd.Series(["未标注"] * len(source_visual))
    source_visual["dataset"] = "source"
    source_visual["label"] = visual_labels.values

    target_visual_base = augmented_target[feature_columns].reset_index(drop=True)
    target_visual_base["dataset"] = "target"
    initial_labels = initial_predictions.get("predicted_label", pd.Series(["未知"] * len(target_visual_base)))
    initial_labels = initial_labels.astype(str)
    target_visual_before = target_visual_base.copy()
    target_visual_before["label"] = [f"预测(初始):{label}" for label in initial_labels]

    combined_before = pd.concat([source_visual, target_visual_before], ignore_index=True)
    alignment_before = compute_domain_alignment_metrics(combined_before)

    final_pipeline = base_result.pipeline
    pseudo_labels = pd.DataFrame()
    pseudo_history: List[Dict[str, float]] = []
    pseudo_quality = pd.DataFrame()

    if config.pseudo_label.enabled:
        LOGGER.info("Applying pseudo-labelling strategy with threshold %.2f", config.pseudo_label.confidence_threshold)
        final_pipeline, pseudo_labels, pseudo_history, pseudo_quality = _apply_pseudo_labelling(
            base_result.pipeline,
            feature_columns,
            augmented_source,
            augmented_target,
            config.diagnosis.label_column,
            config.metadata_columns,
            config.pseudo_label,
        )

    final_predictions = _predict_with_pipeline(
        final_pipeline,
        augmented_target,
        feature_columns,
        config.metadata_columns,
    )

    final_labels = final_predictions.get("predicted_label", pd.Series(["未知"] * len(target_visual_base)))
    final_labels = final_labels.astype(str)
    target_visual_after = target_visual_base.copy()
    target_visual_after["label"] = [f"预测(对齐):{label}" for label in final_labels]

    final_aligned_source = _transform_aligned(final_pipeline, augmented_source[feature_columns].astype(float))
    final_aligned_target = _transform_aligned(final_pipeline, target_matrix)
    final_source_df = pd.DataFrame(final_aligned_source, columns=feature_columns)
    final_source_df["dataset"] = "source_aligned"
    final_source_df["label"] = source_visual["label"].values
    final_target_df = pd.DataFrame(final_aligned_target, columns=feature_columns)
    final_target_df["dataset"] = "target_aligned"
    final_target_df["label"] = target_visual_after["label"].values
    combined_aligned = pd.concat([final_source_df, final_target_df], ignore_index=True)
    alignment_after = compute_domain_alignment_metrics(combined_aligned)

    time_frequency_features = [
        column
        for column in augmented_source.columns
        if column.startswith("tf_") and not column.startswith("tf_consistency_")
    ]
    consistency_features = [column for column in augmented_source.columns if column.startswith("tf_consistency_")]

    return TransferResult(
        base_result=base_result,
        final_pipeline=final_pipeline,
        feature_columns=list(feature_columns),
        modal_feature_groups=modal_feature_groups,
        source_features=augmented_source,
        target_features=augmented_target,
        combined_before=combined_before,
        combined_aligned=combined_aligned,
        alignment_before=alignment_before,
        alignment_after=alignment_after,
        initial_predictions=initial_predictions,
        final_predictions=final_predictions,
        pseudo_labels=pseudo_labels,
        pseudo_label_history=pseudo_history,
        time_frequency_features=time_frequency_features,
        consistency_features=consistency_features,
        pseudo_quality=pseudo_quality,
    )


__all__ = [
    "PseudoLabelConfig",
    "TransferConfig",
    "TransferResult",
    "TimeFrequencyConfig",
    "run_transfer_learning",
    "run_tsne",
]
