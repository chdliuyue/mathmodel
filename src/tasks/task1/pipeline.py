"""High level orchestration utilities for task 1 feature extraction."""
from __future__ import annotations

from dataclasses import dataclass
from pathlib import Path
from typing import Any, Dict, Mapping, Optional

import logging

import pandas as pd

from ...data_io.dataset_selection import SelectionConfig
from ...feature_engineering.feature_extractor import FeatureExtractorConfig
from ...pipelines.build_feature_dataset import (
    SegmentationConfig,
    build_source_feature_table,
    build_target_feature_table,
)

LOGGER = logging.getLogger(__name__)


@dataclass
class FeatureExtractionOutputs:
    """Container bundling DataFrame artefacts generated by task 1."""

    source_features: pd.DataFrame
    source_metadata: pd.DataFrame
    target_features: pd.DataFrame
    target_metadata: pd.DataFrame
    written_paths: Dict[str, Path]


def _parse_segmentation(config: Mapping[str, Any]) -> SegmentationConfig:
    return SegmentationConfig(
        window_seconds=float(config.get("window_seconds", 1.0)),
        overlap=float(config.get("overlap", 0.5)),
        drop_last=bool(config.get("drop_last", True)),
    )


def _parse_feature_config(config: Optional[Mapping[str, Any]]) -> FeatureExtractorConfig:
    if not config:
        return FeatureExtractorConfig()
    return FeatureExtractorConfig(
        include_frequency_domain=bool(config.get("include_frequency_domain", True)),
        include_envelope_domain=bool(config.get("include_envelope_domain", True)),
        include_fault_bands=bool(config.get("include_fault_bands", True)),
        fault_bandwidth=float(config.get("fault_bandwidth", 5.0)),
    )


def _parse_selection_config(config: Mapping[str, Any]) -> SelectionConfig:
    raw_top_k = config.get("top_k_per_label", 10)
    top_k: Optional[int]
    if raw_top_k is None:
        top_k = None
    else:
        if isinstance(raw_top_k, str) and raw_top_k.strip().lower() in {"all", "full", "any"}:
            top_k = None
        else:
            try:
                parsed = int(raw_top_k)
            except (TypeError, ValueError):
                LOGGER.warning("top_k_per_label=%s 无法解析，默认保留全部样本", raw_top_k)
                top_k = None
            else:
                top_k = parsed if parsed > 0 else None
    return SelectionConfig(
        rpm_target=float(config.get("rpm_target", 600.0)),
        sampling_rate_target=float(config.get("sampling_rate_target", 32000.0)),
        top_k_per_label=top_k,
        rpm_weight=float(config.get("rpm_weight", 0.6)),
        sampling_rate_weight=float(config.get("sampling_rate_weight", 0.3)),
        load_weight=float(config.get("load_weight", 0.05)),
        fault_size_weight=float(config.get("fault_size_weight", 0.05)),
        prefer_load=(int(config["prefer_load"]) if config.get("prefer_load") is not None else None),
        prefer_fault_sizes=config.get("prefer_fault_sizes"),
    )


def _ensure_directory(path: Path) -> Path:
    path.mkdir(parents=True, exist_ok=True)
    return path


def run_feature_pipeline(config: Mapping[str, Any], output_dir: Optional[Path] = None) -> FeatureExtractionOutputs:
    """Execute the end-to-end extraction workflow used in task 1."""

    outputs_cfg = config.get("outputs", {}) if isinstance(config, Mapping) else {}
    output_root = output_dir or Path(outputs_cfg.get("directory", "artifacts/task1"))
    _ensure_directory(output_root)

    source_features = pd.DataFrame()
    source_metadata = pd.DataFrame()
    target_features = pd.DataFrame()
    target_metadata = pd.DataFrame()

    written_paths: Dict[str, Path] = {}

    source_cfg = config.get("source") if isinstance(config, Mapping) else None
    if source_cfg:
        segmentation = _parse_segmentation(source_cfg.get("segmentation", {}))
        selection = _parse_selection_config(source_cfg.get("selection", {}))
        feature_cfg = _parse_feature_config(source_cfg.get("feature"))
        root = Path(source_cfg.get("root", "sourceData"))
        channel_bearings = source_cfg.get("channel_bearings", {})
        pattern = source_cfg.get("pattern", "**/*.mat")
        default_sampling_rate = float(source_cfg.get("default_sampling_rate", 12000))

        LOGGER.info("Extracting source-domain features from %s", root)
        source_features, source_metadata = build_source_feature_table(
            root=root,
            segmentation=segmentation,
            selection_config=selection,
            channel_bearings=channel_bearings,
            feature_config=feature_cfg,
            pattern=pattern,
            default_sampling_rate=default_sampling_rate,
        )

        feature_path = output_root / outputs_cfg.get("source_feature_table", "source_features.csv")
        metadata_path = output_root / outputs_cfg.get("source_metadata", "source_metadata.csv")
        if not source_features.empty:
            LOGGER.info("Writing source feature table to %s", feature_path)
            source_features.to_csv(feature_path, index=False, encoding="utf-8-sig")
            written_paths["source_feature_table"] = feature_path
        if not source_metadata.empty:
            LOGGER.info("Writing source metadata table to %s", metadata_path)
            source_metadata.to_csv(metadata_path, index=False, encoding="utf-8-sig")
            written_paths["source_metadata"] = metadata_path

    target_cfg = config.get("target") if isinstance(config, Mapping) else None
    if target_cfg:
        segmentation = _parse_segmentation(target_cfg.get("segmentation", {}))
        feature_cfg = _parse_feature_config(target_cfg.get("feature"))
        root = Path(target_cfg.get("root", "targetData"))
        channel_bearings = target_cfg.get("channel_bearings", {})
        pattern = target_cfg.get("pattern", "*.mat")
        sampling_rate = float(target_cfg.get("sampling_rate", 32000))
        rpm_value = target_cfg.get("rpm")
        rpm = float(rpm_value) if rpm_value is not None else None

        LOGGER.info("Extracting target-domain features from %s", root)
        target_features, target_metadata = build_target_feature_table(
            root=root,
            segmentation=segmentation,
            sampling_rate=sampling_rate,
            rpm=rpm,
            channel_bearings=channel_bearings,
            feature_config=feature_cfg,
            pattern=pattern,
        )

        feature_path = output_root / outputs_cfg.get("target_feature_table", "target_features.csv")
        metadata_path = output_root / outputs_cfg.get("target_metadata", "target_metadata.csv")
        if not target_features.empty:
            LOGGER.info("Writing target feature table to %s", feature_path)
            target_features.to_csv(feature_path, index=False, encoding="utf-8-sig")
            written_paths["target_feature_table"] = feature_path
        if not target_metadata.empty:
            LOGGER.info("Writing target metadata table to %s", metadata_path)
            target_metadata.to_csv(metadata_path, index=False, encoding="utf-8-sig")
            written_paths["target_metadata"] = metadata_path

    return FeatureExtractionOutputs(
        source_features=source_features,
        source_metadata=source_metadata,
        target_features=target_features,
        target_metadata=target_metadata,
        written_paths=written_paths,
    )


__all__ = ["FeatureExtractionOutputs", "run_feature_pipeline"]
